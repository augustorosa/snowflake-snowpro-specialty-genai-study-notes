[< Domain 1 Overview](./README.md) | **1.2 Snowflake Cortex AI Features** | [Vector Data Types >](./1.3_Vector_Data_Types_Operations.md)
***

# 1.2 Snowflake Cortex AI Features

## Overview

Snowflake Cortex provides unified AI capabilities within the Snowflake Data Cloud, offering industry-leading LLMs and ML functions without requiring data movement or complex infrastructure setup.

## Core Cortex Services

### Cortex AI SQL (AISQL)
Industry-leading LLMs from OpenAI, Anthropic, Meta, Mistral AI, and DeepSeek accessible via SQL functions:

#### **Text Generation Functions**
- **AI_COMPLETE / COMPLETE()**: General-purpose text generation
  ```sql
  SELECT SNOWFLAKE.CORTEX.COMPLETE('llama3.1-70b', 'Explain RAG architecture');
  ```

- **CHAT()**: Multi-turn conversational AI
  ```sql
  SELECT SNOWFLAKE.CORTEX.CHAT('mistral-large2', [
      {'role': 'user', 'content': 'What is Snowflake Cortex?'},
      {'role': 'assistant', 'content': 'Previous response...'},
      {'role': 'user', 'content': 'Tell me more about LLM functions.'}
  ]);
  ```

#### **Specialized Task Functions**
- **CLASSIFY_TEXT()**: Text classification into categories
- **SENTIMENT()**: Sentiment analysis (-1 to 1 scale)
- **SUMMARIZE()**: Text summarization
- **TRANSLATE()**: Multi-language translation
- **EXTRACT_ANSWER()**: Question answering from context

#### **Vector Operations**
- **EMBED_TEXT_768()**: 768-dimensional text embeddings
- **EMBED_TEXT_1024()**: 1024-dimensional embeddings
- **VECTOR_COSINE_SIMILARITY()**: Similarity calculations

### Cortex Search
Purpose-built search service for RAG applications:
- Hybrid search (semantic + keyword)
- Built-in chunking and embedding
- Automatic reranking

### Cortex Analyst
Self-service analytics through natural language:
- SQL generation from business questions
- Chart creation and data visualization
- Business intelligence automation

### Document AI
Intelligent document processing:
- **PARSE_DOCUMENT()**: OCR and layout extraction
- Multi-format support (PDF, DOCX, images)
- Structured data extraction

## Available Models

### **Large Models** (High capability, higher cost)
- **claude-4-sonnet**: Premier reasoning and multimodal
- **claude-3-5-sonnet**: Advanced reasoning capabilities
- **mistral-large2**: Top-tier multilingual model
- **llama3.1-405b**: Open source flagship model
- **reka-core**: Strong reasoning and code generation

### **Medium Models** (Balanced performance/cost)
- **llama3.1-70b**: Versatile open source model
- **snowflake-arctic**: Enterprise-optimized LLM
- **mixtral-8x7b**: Fast inference, good quality
- **jamba-instruct**: 256K context window

### **Small Models** (Fast and cost-effective)
- **llama3.1-8b**: Lightweight, 128K context
- **mistral-7b**: High throughput, 32K context
- **gemma-7b**: Simple tasks, very cost-effective

## Access Control

### Required Privileges
```sql
-- Grant Cortex access to role
GRANT DATABASE ROLE SNOWFLAKE.CORTEX_USER TO ROLE my_role;

-- Revoke from PUBLIC if needed
REVOKE DATABASE ROLE SNOWFLAKE.CORTEX_USER FROM ROLE PUBLIC;
```

### Model Access Control
```sql
-- Set account-level model allowlist
ALTER ACCOUNT SET CORTEX_MODELS_ALLOWLIST = 'mistral-large2,llama3.1-70b';

-- Role-based access for specific models
GRANT APPLICATION ROLE SNOWFLAKE."CORTEX-MODEL-ROLE-LLAMA3.1-70B" TO ROLE my_role;
```

## Cost Management

### Token-Based Billing
- Input and output tokens counted for generative functions
- Only input tokens for embedding functions
- Costs vary by model complexity

### Optimization Strategies
```sql
-- Count tokens before processing
SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-8b', 'Your text here');

-- Use appropriate model for task complexity
SELECT SNOWFLAKE.CORTEX.COMPLETE('mistral-7b', simple_prompt) -- For simple tasks
     , SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', complex_prompt) -- For complex reasoning
FROM my_table;
```

### Best Practices
- Use MEDIUM warehouse or smaller for LLM functions
- Cache results when possible
- Choose model size appropriate to task complexity
- Monitor usage with `CORTEX_FUNCTIONS_USAGE_HISTORY`

## Performance Considerations

### Warehouse Sizing
- **Recommended**: SMALL to MEDIUM warehouses
- **Avoid**: Large warehouses (no performance benefit)
- **Cost Impact**: Larger warehouses increase costs without speed gains

### Batch Processing
```sql
-- Process multiple texts efficiently
SELECT id, SNOWFLAKE.CORTEX.SENTIMENT(text_column)
FROM large_table
WHERE date_column >= '2024-01-01';
```

## Regional Availability

### Core Regions
- AWS US West 2 (Oregon)
- AWS US East 1 (N. Virginia)
- AWS Europe Central 1 (Frankfurt)
- Azure East US 2 (Virginia)
- Additional regions for specific functions

### Cross-Region Inference
Enable access to models in other regions when local availability is limited.

## Error Handling

### Common Error Types
```sql
-- Use TRY_COMPLETE for error-safe processing
SELECT SNOWFLAKE.CORTEX.TRY_COMPLETE('llama3.1-70b', potentially_problematic_prompt);

-- Handle token limits
SELECT CASE 
    WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('model', text) < 4000 
    THEN SNOWFLAKE.CORTEX.COMPLETE('model', text)
    ELSE 'Text too long for processing'
END as result;
```

## Integration Examples

### RAG Application Foundation
```sql
-- Create vector storage for documents
CREATE TABLE document_embeddings (
    doc_id INT,
    chunk_text STRING,
    embedding VECTOR(FLOAT, 768)
);

-- Generate embeddings
INSERT INTO document_embeddings
SELECT doc_id, chunk_text,
       SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', chunk_text)
FROM document_chunks;

-- Similarity search
SELECT doc_id, chunk_text,
       VECTOR_COSINE_SIMILARITY(embedding, 
           SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', 'user query')) as similarity
FROM document_embeddings
ORDER BY similarity DESC
LIMIT 5;
```

## Study Questions

1. **Which Cortex function is most appropriate for multi-turn conversations?**
   - A) COMPLETE()
   - B) CHAT()
   - C) EXTRACT_ANSWER()
   - D) CLASSIFY_TEXT()

2. **What is the maximum recommended warehouse size for Cortex LLM functions?**
   - A) SMALL
   - B) MEDIUM
   - C) LARGE
   - D) X-LARGE

3. **Which embedding function creates 768-dimensional vectors?**
   - A) EMBED_TEXT_768()
   - B) EMBED_TEXT_1024()
   - C) Both A and B
   - D) Neither

**Answers: 1-B, 2-B, 3-A**

***
[< Domain 1 Overview](./README.md) | **1.2 Snowflake Cortex AI Features** | [Vector Data Types >](./1.3_Vector_Data_Types_Operations.md) 