[< Domain 4 Overview](./README.md) | **4.1 Document AI Overview** | [Parse Document Function >](./4.2_Parse_Document_Function.md)
***

# 4.1 Document AI Overview

## Overview

Snowflake Document AI provides intelligent document processing capabilities through the `PARSE_DOCUMENT()` function and integrated AI services. This enables extraction of text, layout analysis, and structured data from various document formats including PDFs, Word documents, and images.

## Core Capabilities

### Document Types Supported
- **PDF Files**: Single and multi-page documents
- **Word Documents**: `.docx` format
- **Images**: JPEG, PNG, GIF, BMP, TIFF
- **Scanned Documents**: OCR-enabled processing
- **Mixed Content**: Text, images, tables, forms

### Processing Features
- **Optical Character Recognition (OCR)**: Extract text from images and scanned documents
- **Layout Analysis**: Identify document structure and elements
- **Table Detection**: Recognize and extract tabular data
- **Form Processing**: Extract form fields and values
- **Multi-language Support**: Process documents in various languages

## Document AI Function

### PARSE_DOCUMENT()
Primary function for document processing and text extraction.

```sql
SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
    file_path_or_url,
    options_object  -- Optional
) as parsed_content;
```

### Basic Usage Examples

#### From Staged Files
```sql
-- Parse PDF from internal stage
SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
    '@my_stage/documents/report.pdf'
) as extracted_text;

-- Parse Word document
SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
    '@document_stage/contracts/agreement.docx'
) as document_content;
```

#### From External URLs
```sql
-- Parse document from external URL
SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
    'https://example.com/public/document.pdf'
) as url_content;
```

#### With Options
```sql
-- Parse with specific options
SELECT SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
    '@my_stage/forms/application.pdf',
    {'extract_tables': true, 'extract_forms': true}
) as structured_content;
```

## Output Structure

### Standard Output Format
The function returns a VARIANT object containing:

```json
{
  "text": "Full extracted text content",
  "pages": [
    {
      "page_number": 1,
      "text": "Page 1 content",
      "tables": [...],
      "forms": [...],
      "images": [...]
    }
  ],
  "metadata": {
    "page_count": 3,
    "document_type": "PDF",
    "processing_time_ms": 1234
  }
}
```

### Extracting Components
```sql
-- Extract different components from parsed document
SELECT 
    file_name,
    parsed_content:text::STRING as full_text,
    parsed_content:metadata:page_count::INTEGER as page_count,
    parsed_content:pages[0].text::STRING as first_page_text,
    parsed_content:pages[0].tables as first_page_tables
FROM (
    SELECT 
        'report.pdf' as file_name,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT('@docs/report.pdf') as parsed_content
);
```

## Batch Document Processing

### Processing Multiple Documents
```sql
-- Process all documents in a stage
CREATE TABLE document_extractions AS
SELECT 
    file_name,
    file_size,
    SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path) as parsed_content,
    CURRENT_TIMESTAMP() as processed_at
FROM (
    SELECT 
        METADATA$FILENAME as file_name,
        METADATA$FILE_SIZE as file_size,
        '@document_stage/' || METADATA$FILENAME as file_path
    FROM TABLE(RESULT_SCAN(LAST_QUERY_ID()))
);
```

### Scheduled Processing Pipeline
```sql
-- Create procedure for regular document processing
CREATE OR REPLACE PROCEDURE process_new_documents()
RETURNS STRING
LANGUAGE SQL
AS $$
DECLARE
    processed_count INTEGER := 0;
BEGIN
    -- Process new documents
    INSERT INTO processed_documents
    SELECT 
        file_name,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path) as content,
        CURRENT_TIMESTAMP() as processed_at
    FROM pending_documents
    WHERE processed = FALSE;
    
    -- Mark as processed
    UPDATE pending_documents 
    SET processed = TRUE 
    WHERE processed = FALSE;
    
    SELECT COUNT(*) INTO processed_count FROM pending_documents;
    RETURN 'Processed ' || processed_count || ' documents';
END;
$$;
```

## Advanced Processing Options

### Table Extraction
```sql
-- Focus on table extraction
SELECT 
    doc_id,
    table_data
FROM (
    SELECT 
        doc_id,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
            file_path,
            {'extract_tables': true, 'table_format': 'structured'}
        ) as parsed_doc
    FROM documents
),
LATERAL FLATTEN(parsed_doc:pages) as pages,
LATERAL FLATTEN(pages.value:tables) as table_data;
```

### Form Field Extraction
```sql
-- Extract form fields and values
SELECT 
    document_id,
    form_field.value:field_name::STRING as field_name,
    form_field.value:field_value::STRING as field_value,
    form_field.value:confidence::FLOAT as confidence
FROM (
    SELECT 
        document_id,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
            document_path,
            {'extract_forms': true}
        ) as parsed_content
    FROM form_documents
),
LATERAL FLATTEN(parsed_content:pages) as pages,
LATERAL FLATTEN(pages.value:forms) as form_field;
```

### Multi-language Processing
```sql
-- Process documents in different languages
SELECT 
    document_id,
    language,
    SNOWFLAKE.CORTEX.PARSE_DOCUMENT(
        file_path,
        {'language': language, 'ocr_language': language}
    ) as extracted_content
FROM multilingual_documents;
```

## Integration with Other Cortex Functions

### Text Analysis Pipeline
```sql
-- Complete document analysis pipeline
WITH document_extraction AS (
    SELECT 
        doc_id,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path) as parsed_doc
    FROM source_documents
),
text_analysis AS (
    SELECT 
        doc_id,
        parsed_doc:text::STRING as full_text,
        SNOWFLAKE.CORTEX.SENTIMENT(parsed_doc:text::STRING) as sentiment,
        SNOWFLAKE.CORTEX.SUMMARIZE(parsed_doc:text::STRING) as summary
    FROM document_extraction
    WHERE LENGTH(parsed_doc:text::STRING) > 100
)
SELECT 
    doc_id,
    full_text,
    sentiment,
    summary,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768(
        'snowflake-arctic-embed-m',
        summary
    ) as summary_embedding
FROM text_analysis;
```

### RAG Implementation with Documents
```sql
-- Document-based RAG system
WITH document_chunks AS (
    SELECT 
        doc_id,
        page_num,
        page_content,
        SNOWFLAKE.CORTEX.EMBED_TEXT_768(
            'snowflake-arctic-embed-m',
            page_content
        ) as page_embedding
    FROM (
        SELECT 
            doc_id,
            pages.index as page_num,
            pages.value:text::STRING as page_content
        FROM (
            SELECT 
                doc_id,
                SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path) as parsed_doc
            FROM documents
        ),
        LATERAL FLATTEN(parsed_doc:pages) as pages
    )
    WHERE LENGTH(page_content) > 50
)
INSERT INTO document_embeddings SELECT * FROM document_chunks;
```

### Question Answering from Documents
```sql
-- Answer questions using document content
WITH relevant_content AS (
    SELECT 
        doc_id,
        page_content,
        VECTOR_COSINE_SIMILARITY(
            page_embedding,
            SNOWFLAKE.CORTEX.EMBED_TEXT_768('snowflake-arctic-embed-m', ?)
        ) as relevance_score
    FROM document_embeddings
    ORDER BY relevance_score DESC
    LIMIT 3
),
context_assembly AS (
    SELECT LISTAGG(page_content, '\n\n') as context
    FROM relevant_content
)
SELECT SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
    context,
    ?  -- User question
) as answer
FROM context_assembly;
```

## Performance Considerations

### File Size Limits
- **Maximum file size**: 50MB per document
- **Recommended size**: Under 10MB for optimal performance
- **Large documents**: Consider splitting into smaller chunks

### Processing Time
- **Simple PDFs**: 1-5 seconds
- **Complex documents with tables/forms**: 10-30 seconds
- **High-resolution images**: 15-60 seconds

### Cost Optimization
```sql
-- Monitor Document AI usage
SELECT 
    DATE_TRUNC('day', timestamp) as date,
    COUNT(*) as documents_processed,
    SUM(CASE WHEN status = 'success' THEN 1 ELSE 0 END) as successful_processing,
    AVG(processing_time_ms) as avg_processing_time,
    SUM(input_size_bytes) as total_input_size
FROM TABLE(INFORMATION_SCHEMA.DOCUMENT_AI_USAGE_HISTORY(
    DATE_ADD('day', -30, CURRENT_DATE()),
    CURRENT_DATE()
))
GROUP BY 1
ORDER BY 1 DESC;
```

## Error Handling

### Common Error Scenarios
```sql
-- Robust document processing with error handling
SELECT 
    file_name,
    CASE 
        WHEN file_size > 50 * 1024 * 1024 THEN 'File too large'
        WHEN file_extension NOT IN ('pdf', 'docx', 'jpg', 'png') THEN 'Unsupported format'
        ELSE 
            TRY_CAST(
                SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path) AS VARIANT
            )
    END as processing_result
FROM document_queue;
```

### Retry Logic
```sql
-- Implement retry mechanism for failed documents
CREATE OR REPLACE PROCEDURE retry_failed_documents()
RETURNS STRING
LANGUAGE SQL
AS $$
DECLARE
    retry_count INTEGER := 0;
BEGIN
    -- Retry documents that failed processing
    UPDATE document_processing_log
    SET 
        parsed_content = SNOWFLAKE.CORTEX.PARSE_DOCUMENT(file_path),
        processing_status = 'success',
        retry_count = retry_count + 1,
        last_attempt = CURRENT_TIMESTAMP()
    WHERE processing_status = 'failed' 
    AND retry_count < 3
    AND DATEDIFF('hour', last_attempt, CURRENT_TIMESTAMP()) >= 1;
    
    SELECT COUNT(*) INTO retry_count 
    FROM document_processing_log 
    WHERE processing_status = 'success' 
    AND last_attempt >= DATEADD('minute', -5, CURRENT_TIMESTAMP());
    
    RETURN 'Successfully processed ' || retry_count || ' documents on retry';
END;
$$;
```

## Use Cases

### Contract Analysis
```sql
-- Extract key information from contracts
SELECT 
    contract_id,
    extracted_text:text::STRING as full_contract_text,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        extracted_text:text::STRING,
        'What is the contract duration?'
    ) as contract_duration,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        extracted_text:text::STRING,
        'What are the payment terms?'
    ) as payment_terms
FROM (
    SELECT 
        contract_id,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(contract_file_path) as extracted_text
    FROM legal_contracts
);
```

### Invoice Processing
```sql
-- Process invoices and extract structured data
SELECT 
    invoice_id,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        parsed_content:text::STRING,
        'What is the invoice total amount?'
    ) as invoice_total,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        parsed_content:text::STRING,
        'What is the invoice date?'
    ) as invoice_date,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        parsed_content:text::STRING,
        'Who is the vendor?'
    ) as vendor_name
FROM (
    SELECT 
        invoice_id,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(invoice_file_path) as parsed_content
    FROM invoices
);
```

### Research Document Processing
```sql
-- Process research papers and create knowledge base
SELECT 
    paper_id,
    title,
    SNOWFLAKE.CORTEX.SUMMARIZE(
        parsed_content:text::STRING
    ) as abstract_summary,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768(
        'snowflake-arctic-embed-m',
        parsed_content:text::STRING
    ) as paper_embedding
FROM (
    SELECT 
        paper_id,
        title,
        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(paper_file_path) as parsed_content
    FROM research_papers
);
```

## Study Questions

1. **What is the maximum file size supported by PARSE_DOCUMENT()?**
   - A) 10MB
   - B) 25MB
   - C) 50MB
   - D) 100MB

2. **Which document formats are supported by Document AI?**
   - A) Only PDF
   - B) PDF and Word only
   - C) PDF, Word, and images
   - D) All text-based formats

3. **What type of data structure does PARSE_DOCUMENT() return?**
   - A) STRING
   - B) ARRAY
   - C) VARIANT
   - D) OBJECT

**Answers: 1-C, 2-C, 3-C**

***
[< Domain 4 Overview](./README.md) | **4.1 Document AI Overview** | [Parse Document Function >](./4.2_Parse_Document_Function.md) 