[< Domain 2](./README.md) | **ðŸ“˜ 2.1 Cortex LLM Functions** | [2.2 Text Generation >](./2.2_Text_Generation_Functions.md)
***

# 2.1 Cortex LLM Functions Overview

This section provides a comprehensive guide to Snowflake Cortex LLM functions, their syntax, parameters, and practical applications. These functions are the core building blocks for implementing generative AI solutions in Snowflake.

## Function Categories

Snowflake Cortex functions are organized into several categories. The latest AI_* functions are recommended for new implementations:

### **Latest AI Functions (Recommended)**
- `AI_COMPLETE()` - Updated text completion with latest models and features
- `AI_CLASSIFY()` - Enhanced classification with multi-label and image support
- `AI_FILTER()` - Boolean filtering with natural language conditions
- `AI_AGG()` - Aggregate insights across multiple rows without context limits
- `AI_SUMMARIZE_AGG()` - Aggregate summaries across multiple rows
- `AI_SIMILARITY()` - Calculate embedding similarity between inputs

### **Legacy Functions (Still Supported)**
- `COMPLETE()` - Original text completion and generation
- `CHAT()` - Conversational AI and multi-turn conversations
- `SENTIMENT()` - Sentiment analysis and scoring
- `EXTRACT_ANSWER()` - Question answering from context
- `CLASSIFY()` - Text classification and categorization
- `SUMMARIZE()` - Text summarization
- `TRANSLATE()` - Language translation
- `PARSE_DOCUMENT()` - Document parsing and structure extraction

### **Embedding Functions**
- `EMBED_TEXT_768()` - 768-dimensional text embeddings
- `EMBED_TEXT_1024()` - 1024-dimensional text embeddings

### **Utility Functions**
- `COUNT_TOKENS()` - Token counting for cost estimation
- `TRY_COMPLETE()` - Error-safe completion function

## Complete Function Reference

### **AI_COMPLETE()** [Latest - Recommended]
âš ï¸ **Important Notice**: The AI_* functions (AI_COMPLETE, AI_CLASSIFY, AI_FILTER, AI_AGG, AI_SIMILARITY) are currently in preview and are **NOT included in the SnowPro Specialty: Gen AI certification exam**. Focus on the SNOWFLAKE.CORTEX.* functions for exam preparation.

The updated and most versatile function for text generation and completion tasks, with support for the latest models.

**Syntax:**
```sql
AI_COMPLETE(
    model_name,
    prompt,
    [options]
)
```

**Parameters:**
- `model_name` (STRING): The LLM model to use
- `prompt` (STRING): The input prompt text  
- `options` (OBJECT): Optional parameters (temperature, max_tokens, etc.)

**Examples:**

```sql
-- Using latest models
SELECT AI_COMPLETE(
    'claude-3.5-sonnet',
    'Write a brief explanation of machine learning'
) AS explanation;

SELECT AI_COMPLETE(
    'gpt-4o',
    'Generate a Python function for data validation'
) AS python_code;

-- With advanced options
SELECT AI_COMPLETE(
    'llama3.1-405b',
    'Analyze the following data trends...',
    {'temperature': 0.1, 'max_tokens': 500}
) AS analysis;
```

### **SNOWFLAKE.CORTEX.COMPLETE()** [Legacy - Still Supported]

The most versatile function for text generation and completion tasks.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.COMPLETE(
    model_name,
    prompt,
    [options]
)
```

**Parameters:**
- `model_name` (STRING): The LLM model to use
- `prompt` (STRING): The input prompt text
- `options` (OBJECT): Optional parameters (temperature, max_tokens, etc.)

**Available Models:**

**Large Models (Best Performance):**
- `'llama3.1-405b'` - Meta's largest model for complex reasoning
- `'claude-3.5-sonnet'` - Anthropic's advanced model for sophisticated tasks
- `'gpt-4o'` - OpenAI's flagship multimodal model
- `'mistral-large2'` - Mistral's most capable model

**Medium Models (Balanced Performance/Cost):**
- `'llama3.1-70b'` - Strong performance for most use cases
- `'claude-3-haiku'` - Fast and cost-effective from Anthropic
- `'gpt-4o-mini'` - OpenAI's efficient model
- `'mixtral-8x7b'` - Mixture of experts model
- `'mistral-7b'` - General-purpose model

**Small Models (Cost-Optimized):**
- `'llama3.1-8b'` - Lightweight but capable
- `'gemma-7b'` - Google's efficient model
- `'llama2-70b-chat'` - Optimized for conversations
- `'llama2-7b-chat'` - Lightweight conversational model
- `'deepseek-coder-6.7b'` - Specialized for code generation

**Examples:**

```sql
-- Basic text completion
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'mistral-large',
    'Write a brief explanation of machine learning:'
) AS explanation;

-- Code generation
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'mistral-large',
    'Write a Python function that calculates the factorial of a number:'
) AS python_code;

-- Creative writing
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama2-70b-chat',
    'Write a short story about a robot learning to paint:'
) AS short_story;

-- With options
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'mistral-large',
    'Summarize the benefits of cloud computing',
    {'temperature': 0.3, 'max_tokens': 200}
) AS summary;
```

### **SNOWFLAKE.CORTEX.CHAT()**

Specialized function for conversational AI with multi-turn conversation support.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.CHAT(
    model_name,
    messages,
    [options]
)
```

**Parameters:**
- `model_name` (STRING): The chat-optimized model to use  
- `messages` (ARRAY): Array of message objects with role and content
- `options` (OBJECT): Optional parameters

**Message Format:**
```json
[
    {"role": "system", "content": "You are a helpful assistant"},
    {"role": "user", "content": "What is AI?"},
    {"role": "assistant", "content": "AI stands for..."},
    {"role": "user", "content": "Can you give examples?"}
]
```

**Examples:**

```sql
-- Simple chat interaction
SELECT SNOWFLAKE.CORTEX.CHAT(
    'llama2-70b-chat',
    [
        {'role': 'system', 'content': 'You are a SQL expert assistant'},
        {'role': 'user', 'content': 'How do I create a table in Snowflake?'}
    ]
) AS chat_response;

-- Multi-turn conversation
SELECT SNOWFLAKE.CORTEX.CHAT(
    'mistral-large',
    [
        {'role': 'system', 'content': 'You are a data analyst'},
        {'role': 'user', 'content': 'What is customer churn?'},
        {'role': 'assistant', 'content': 'Customer churn refers to when customers stop using your service'},
        {'role': 'user', 'content': 'How can we predict it?'}
    ]
) AS prediction_advice;

-- Customer service chatbot
WITH conversation_history AS (
    SELECT [
        {'role': 'system', 'content': 'You are a customer service representative'},
        {'role': 'user', 'content': customer_query}
    ] AS messages
    FROM customer_inquiries
    WHERE ticket_id = 12345
)
SELECT SNOWFLAKE.CORTEX.CHAT(
    'llama2-70b-chat',
    messages
) AS response
FROM conversation_history;
```

### **SNOWFLAKE.CORTEX.SENTIMENT()**

Analyzes the sentiment of text and returns a score.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.SENTIMENT(text)
```

**Parameters:**
- `text` (STRING): Text to analyze for sentiment

**Returns:** Float between -1 (negative) and 1 (positive)

**Examples:**

```sql
-- Analyze customer review sentiment
SELECT 
    review_id,
    review_text,
    SNOWFLAKE.CORTEX.SENTIMENT(review_text) AS sentiment_score,
    CASE 
        WHEN SNOWFLAKE.CORTEX.SENTIMENT(review_text) > 0.1 THEN 'Positive'
        WHEN SNOWFLAKE.CORTEX.SENTIMENT(review_text) < -0.1 THEN 'Negative'
        ELSE 'Neutral'
    END AS sentiment_category
FROM customer_reviews;

-- Monitor social media mentions
SELECT 
    DATE_TRUNC('day', post_date) AS day,
    AVG(SNOWFLAKE.CORTEX.SENTIMENT(post_content)) AS avg_sentiment,
    COUNT(*) AS post_count
FROM social_media_mentions
WHERE brand_mentioned = 'YourBrand'
GROUP BY DATE_TRUNC('day', post_date)
ORDER BY day;
```

### **SNOWFLAKE.CORTEX.EXTRACT_ANSWER()**

Extracts specific answers from text based on questions.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.EXTRACT_ANSWER(question, context)
```

**Parameters:**
- `question` (STRING): The question to ask
- `context` (STRING): The context text to search for answers

**Examples:**

```sql
-- Extract information from documents
SELECT 
    document_id,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        'What is the contract value?',
        document_text
    ) AS contract_value,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
        'When does the contract expire?',
        document_text
    ) AS expiration_date
FROM legal_documents
WHERE document_type = 'CONTRACT';

-- FAQ automation
WITH faqs AS (
    SELECT 
        'What are your business hours?' AS question,
        'Our customer service is available Monday through Friday, 9 AM to 6 PM EST.' AS context
    UNION ALL
    SELECT 
        'What is your return policy?' AS question,
        'We offer a 30-day return policy for all unused items in original packaging.' AS context
)
SELECT 
    question,
    SNOWFLAKE.CORTEX.EXTRACT_ANSWER(question, context) AS answer
FROM faqs;
```

### **AI_CLASSIFY()** [Latest - Recommended]

Enhanced classification function with support for text, images, and multi-label classification.

**Syntax:**
```sql
AI_CLASSIFY(
    input,
    categories,
    [options]
)
```

**Parameters:**
- `input` (STRING or OBJECT): Text to classify or image reference
- `categories` (ARRAY): Array of possible categories (up to 500)
- `options` (OBJECT): Optional parameters for multi-label classification

**Examples:**

```sql
-- Text classification with multiple labels
SELECT AI_CLASSIFY(
    'This restaurant has great food but terrible service',
    ['food_quality', 'service_quality', 'price', 'ambiance'],
    {'multi_label': true}
) AS classifications;

-- Simple categorization
SELECT AI_CLASSIFY(
    review_text,
    ['positive', 'negative', 'neutral']
) AS sentiment_category
FROM customer_reviews;

-- Image classification (when supported)
SELECT AI_CLASSIFY(
    {'image_url': 'https://example.com/image.jpg'},
    ['cat', 'dog', 'bird', 'other']
) AS image_classification;
```

### **SNOWFLAKE.CORTEX.CLASSIFY()** [Legacy - Still Supported]

Original classification function for text into predefined categories.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.CLASSIFY(text, categories)
```

**Parameters:**
- `text` (STRING): Text to classify
- `categories` (ARRAY): Array of possible categories

**Examples:**

```sql
-- Classify customer tickets
SELECT 
    ticket_id,
    ticket_description,
    SNOWFLAKE.CORTEX.CLASSIFY(
        ticket_description,
        ['billing', 'technical', 'account', 'general']
    ) AS ticket_category
FROM support_tickets;

-- Email classification
SELECT 
    email_id,
    subject_line,
    email_body,
    SNOWFLAKE.CORTEX.CLASSIFY(
        subject_line || ' ' || email_body,
        ['urgent', 'normal', 'low_priority', 'spam']
    ) AS email_priority
FROM incoming_emails;

-- Product categorization
SELECT 
    product_id,
    product_description,
    SNOWFLAKE.CORTEX.CLASSIFY(
        product_description,
        ['electronics', 'clothing', 'home_garden', 'books', 'sports']
    ) AS product_category
FROM products
WHERE category IS NULL;
```

### **SNOWFLAKE.CORTEX.SUMMARIZE()**

Generates concise summaries of long text.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.SUMMARIZE(text, [length])
```

**Parameters:**
- `text` (STRING): Text to summarize
- `length` (STRING): 'short', 'medium', or 'long' (optional)

**Examples:**

```sql
-- Summarize news articles
SELECT 
    article_id,
    headline,
    SNOWFLAKE.CORTEX.SUMMARIZE(article_content, 'short') AS short_summary,
    SNOWFLAKE.CORTEX.SUMMARIZE(article_content, 'medium') AS detailed_summary
FROM news_articles
WHERE publish_date >= CURRENT_DATE - 7;

-- Meeting minutes summarization
SELECT 
    meeting_id,
    meeting_date,
    SNOWFLAKE.CORTEX.SUMMARIZE(
        meeting_transcript,
        'medium'
    ) AS meeting_summary
FROM meeting_transcripts;

-- Research paper abstracts
SELECT 
    paper_id,
    title,
    SNOWFLAKE.CORTEX.SUMMARIZE(full_text, 'short') AS auto_abstract
FROM research_papers
WHERE abstract IS NULL;
```

### **SNOWFLAKE.CORTEX.TRANSLATE()**

Translates text between different languages.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.TRANSLATE(text, source_language, target_language)
```

**Parameters:**
- `text` (STRING): Text to translate
- `source_language` (STRING): Source language code (e.g., 'en', 'es', 'fr')
- `target_language` (STRING): Target language code

**Supported Languages:**
- `'en'` - English
- `'es'` - Spanish  
- `'fr'` - French
- `'de'` - German
- `'it'` - Italian
- `'pt'` - Portuguese
- `'zh'` - Chinese
- `'ja'` - Japanese
- `'ko'` - Korean

**Examples:**

```sql
-- Translate customer reviews
SELECT 
    review_id,
    original_text,
    source_language,
    SNOWFLAKE.CORTEX.TRANSLATE(
        original_text,
        source_language,
        'en'
    ) AS english_translation
FROM international_reviews
WHERE source_language != 'en';

-- Multi-language support table
CREATE TABLE translated_content AS
SELECT 
    content_id,
    original_content,
    'en' AS source_lang,
    'es' AS target_lang,
    SNOWFLAKE.CORTEX.TRANSLATE(original_content, 'en', 'es') AS spanish_content
FROM english_content
UNION ALL
SELECT 
    content_id,
    original_content,
    'en' AS source_lang,
    'fr' AS target_lang,
    SNOWFLAKE.CORTEX.TRANSLATE(original_content, 'en', 'fr') AS french_content
FROM english_content;
```

### **AI_FILTER()** [New Function]

Evaluates natural language conditions and returns TRUE or FALSE for filtering data.

**Syntax:**
```sql
AI_FILTER(
    condition,
    input
)
```

**Parameters:**
- `condition` (STRING): Natural language condition to evaluate
- `input` (STRING or OBJECT): Text or data to evaluate

**Examples:**

```sql
-- Filter reviews about specific topics
SELECT *
FROM customer_reviews 
WHERE AI_FILTER(
    'Is this review about product quality?',
    review_text
) = TRUE;

-- Tag content with boolean flags
SELECT 
    post_content,
    AI_FILTER('Is this post positive?', post_content) AS is_positive,
    AI_FILTER('Does this mention a competitor?', post_content) AS mentions_competitor
FROM social_media_posts;

-- Filter with dynamic conditions
SELECT *
FROM support_tickets
WHERE AI_FILTER(
    'Is this an urgent technical issue?',
    ticket_description
) = TRUE;
```

### **AI_AGG()** [New Function]

Aggregates text data and returns insights across multiple rows without context window limitations.

**Syntax:**
```sql
AI_AGG(
    text_column,
    instruction
)
```

**Parameters:**
- `text_column` (STRING): Column containing text to aggregate
- `instruction` (STRING): Natural language instruction for aggregation

**Examples:**

```sql
-- Summarize feedback by product category
SELECT 
    product_category,
    AI_AGG(
        customer_feedback,
        'Summarize the main themes and sentiment in customer feedback'
    ) AS feedback_summary
FROM reviews
GROUP BY product_category;

-- Extract key insights from support tickets
SELECT 
    DATE_TRUNC('month', created_date) AS month,
    AI_AGG(
        issue_description,
        'Identify the top 3 most common technical issues reported'
    ) AS top_issues
FROM support_tickets
GROUP BY DATE_TRUNC('month', created_date);

-- Analyze sales call notes
SELECT 
    sales_rep,
    AI_AGG(
        call_notes,
        'Extract key objections and concerns raised by prospects'
    ) AS common_objections
FROM sales_calls
WHERE call_date >= CURRENT_DATE - 30
GROUP BY sales_rep;
```

### **AI_SIMILARITY()** [New Function]

Calculates embedding similarity between two text inputs.

**Syntax:**
```sql
AI_SIMILARITY(
    text1,
    text2
)
```

**Parameters:**
- `text1` (STRING): First text input
- `text2` (STRING): Second text input

**Examples:**

```sql
-- Find similar product descriptions
SELECT 
    p1.product_name,
    p2.product_name,
    AI_SIMILARITY(p1.description, p2.description) AS similarity_score
FROM products p1
CROSS JOIN products p2
WHERE p1.product_id < p2.product_id
AND AI_SIMILARITY(p1.description, p2.description) > 0.8;

-- Compare customer inquiries to FAQ content
SELECT 
    inquiry_id,
    faq_question,
    AI_SIMILARITY(customer_question, faq_question) AS relevance_score
FROM customer_inquiries ci
CROSS JOIN faq_database faq
WHERE AI_SIMILARITY(ci.customer_question, faq.faq_question) > 0.7
ORDER BY relevance_score DESC;
```

### **SNOWFLAKE.CORTEX.EMBED_TEXT_768()**

Generates 768-dimensional embeddings for text.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.EMBED_TEXT_768(model_name, text)
```

**Parameters:**
- `model_name` (STRING): Embedding model name
- `text` (STRING): Text to embed

**Available Models:**
- `'snowflake-arctic-embed-l'` - Snowflake's large embedding model (best performance)
- `'snowflake-arctic-embed-m'` - Snowflake's medium embedding model (balanced)
- `'e5-base-v2'` - General purpose 768-dimensional embeddings
- `'multilingual-e5-large'` - Multi-language embedding support

**Examples:**

```sql
-- Create document embeddings
CREATE TABLE document_embeddings AS
SELECT 
    document_id,
    title,
    content,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', content) AS embedding
FROM documents;

-- Semantic search implementation
WITH query_embedding AS (
    SELECT SNOWFLAKE.CORTEX.EMBED_TEXT_768(
        'e5-base-v2',
        'artificial intelligence machine learning'
    ) AS query_vector
)
SELECT 
    d.document_id,
    d.title,
    VECTOR_COSINE_SIMILARITY(d.embedding, q.query_vector) AS similarity
FROM document_embeddings d
CROSS JOIN query_embedding q
ORDER BY similarity DESC
LIMIT 10;
```

### **SNOWFLAKE.CORTEX.COUNT_TOKENS()**

Counts tokens in text for cost estimation.

**Syntax:**
```sql
SNOWFLAKE.CORTEX.COUNT_TOKENS(model_name, text)
```

**Examples:**

```sql
-- Estimate processing costs
SELECT 
    prompt_id,
    prompt_text,
    SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-large', prompt_text) AS token_count,
    SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-large', prompt_text) * 0.001 AS estimated_cost
FROM prompt_templates;

-- Monitor token usage
SELECT 
    DATE_TRUNC('day', query_date) AS day,
    SUM(SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-large', input_text)) AS total_tokens
FROM llm_usage_log
GROUP BY DATE_TRUNC('day', query_date)
ORDER BY day;
```

## Best Practices

### **Function Selection**
1. Use `COMPLETE()` for general text generation tasks
2. Use `CHAT()` for conversational interfaces
3. Use specialized functions (`SENTIMENT()`, `CLASSIFY()`) for specific analysis tasks
4. Choose appropriate models based on complexity and cost requirements

### **Performance Optimization**
1. Process multiple records in batch operations
2. Use appropriate model sizes for your use case
3. Cache results when possible
4. Monitor token usage and costs

### **Error Handling**
```sql
-- Robust function calls with error handling
SELECT 
    id,
    text_content,
    TRY_TO_TEXT(SNOWFLAKE.CORTEX.SENTIMENT(text_content)) AS sentiment,
    CASE 
        WHEN TRY_TO_TEXT(SNOWFLAKE.CORTEX.SENTIMENT(text_content)) IS NULL 
        THEN 'Error processing text'
        ELSE 'Success'
    END AS processing_status
FROM input_data;
```

### **Cost Management**
```sql
-- Token counting before processing
WITH token_analysis AS (
    SELECT 
        id,
        input_text,
        SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-large', input_text) AS tokens
    FROM processing_queue
)
SELECT *
FROM token_analysis
WHERE tokens <= 1000  -- Process only items within token limit
ORDER BY tokens;
```

---

**Next Steps**: Continue to [2.2 Text Generation Functions](./2.2_Text_Generation_Functions.md) to dive deeper into specific text generation use cases and advanced techniques.

***
[< Domain 2](./README.md) | **ðŸ“˜ 2.1 Cortex LLM Functions** | [2.2 Text Generation >](./2.2_Text_Generation_Functions.md) 