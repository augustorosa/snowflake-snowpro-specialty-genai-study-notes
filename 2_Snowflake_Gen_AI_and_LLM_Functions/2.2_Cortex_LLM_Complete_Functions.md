[< Domain 2 Overview](./README.md) | **2.2 Cortex LLM Complete Functions** | [Cortex Chat Functions >](./2.3_Cortex_Chat_Functions.md)
***

# 2.2 Cortex LLM Complete Functions

## Overview

Snowflake Cortex LLM Complete functions provide text generation capabilities through industry-leading large language models. These functions enable single-turn text generation for various use cases including content creation, code generation, analysis, and transformation.

## Core Complete Functions

### COMPLETE()
Primary text generation function for single-turn completions.

```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    model_name,
    prompt,
    options_object  -- Optional
) as completion;
```

### TRY_COMPLETE()
Error-safe variant that returns NULL instead of throwing errors.

```sql
SELECT SNOWFLAKE.CORTEX.TRY_COMPLETE(
    'llama3.1-70b',
    potentially_problematic_prompt
) as safe_completion;
```

## Available Models for Complete Functions

### **Large Models** (Complex reasoning, highest capability)
```sql
-- Claude models - Superior reasoning and analysis
SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', prompt)  -- Best overall performance
SNOWFLAKE.CORTEX.COMPLETE('claude-4-sonnet', prompt)    -- Multimodal capabilities

-- Mistral models - Multilingual excellence
SNOWFLAKE.CORTEX.COMPLETE('mistral-large2', prompt)     -- Top-tier performance

-- LLaMA models - Open source power
SNOWFLAKE.CORTEX.COMPLETE('llama3.1-405b', prompt)     -- Largest open model
SNOWFLAKE.CORTEX.COMPLETE('llama3.1-70b', prompt)      -- Balanced performance

-- Specialized models
SNOWFLAKE.CORTEX.COMPLETE('reka-core', prompt)         -- Code generation focus
```

### **Medium Models** (Balanced performance/cost)
```sql
-- Efficient models for most tasks
SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', prompt)   -- Enterprise-optimized
SNOWFLAKE.CORTEX.COMPLETE('mixtral-8x7b', prompt)      -- Fast inference
SNOWFLAKE.CORTEX.COMPLETE('jamba-instruct', prompt)    -- 256K context window
```

### **Small Models** (Fast and cost-effective)
```sql
-- For simple tasks and high throughput
SNOWFLAKE.CORTEX.COMPLETE('llama3.1-8b', prompt)       -- 128K context
SNOWFLAKE.CORTEX.COMPLETE('mistral-7b', prompt)        -- 32K context  
SNOWFLAKE.CORTEX.COMPLETE('gemma-7b', prompt)          -- Very cost-effective
```

## Function Options

### Temperature Control
Controls randomness in generation (0.0 = deterministic, 1.0 = very random).

```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama3.1-70b',
    'Write a creative story about AI.',
    {'temperature': 0.8}  -- More creative
) as creative_response;

SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'claude-3-5-sonnet',
    'What is 2+2?',
    {'temperature': 0.0}  -- Deterministic
) as factual_response;
```

### Max Tokens
Limits the length of generated responses.

```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'mistral-large2',
    'Explain machine learning in detail.',
    {'max_tokens': 200}  -- Limit to ~200 tokens
) as brief_explanation;
```

### Top-P (Nucleus Sampling)
Controls diversity by limiting token selection to top probability mass.

```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama3.1-70b',
    'Generate product descriptions.',
    {
        'temperature': 0.7,
        'top_p': 0.9  -- Consider tokens up to 90% cumulative probability
    }
) as balanced_generation;
```

## Common Use Cases

### Content Generation

#### Product Descriptions
```sql
-- Generate product descriptions from features
SELECT 
    product_id,
    product_name,
    SNOWFLAKE.CORTEX.COMPLETE(
        'claude-3-5-sonnet',
        CONCAT(
            'Write a compelling product description for: ',
            product_name, '. Features: ', features,
            '. Target audience: ', target_audience,
            '. Tone: professional and engaging.'
        ),
        {'temperature': 0.7, 'max_tokens': 150}
    ) as generated_description
FROM products
WHERE description IS NULL;
```

#### Email Templates
```sql
-- Generate personalized email templates
SELECT 
    customer_id,
    SNOWFLAKE.CORTEX.COMPLETE(
        'mistral-large2',
        CONCAT(
            'Write a professional follow-up email for customer: ',
            customer_name, ' who purchased: ', product_name,
            ' on ', purchase_date::STRING,
            '. Include thank you and support information.'
        )
    ) as follow_up_email
FROM recent_purchases;
```

### Data Analysis & Insights

#### Text Analysis
```sql
-- Analyze customer feedback
SELECT 
    feedback_id,
    customer_feedback,
    SNOWFLAKE.CORTEX.COMPLETE(
        'claude-3-5-sonnet',
        CONCAT(
            'Analyze this customer feedback and provide insights: "',
            customer_feedback, '"',
            ' Identify: 1) Main concerns 2) Sentiment 3) Actionable items'
        )
    ) as feedback_analysis
FROM customer_feedback
WHERE analysis IS NULL;
```

#### Report Generation
```sql
-- Generate executive summaries
WITH sales_metrics AS (
    SELECT 
        SUM(revenue) as total_revenue,
        COUNT(*) as total_orders,
        AVG(order_value) as avg_order_value
    FROM sales_data
    WHERE date >= '2024-01-01'
)
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama3.1-70b',
    CONCAT(
        'Create an executive summary for Q1 2024 sales performance: ',
        'Total Revenue: $', total_revenue::STRING,
        ', Total Orders: ', total_orders::STRING,
        ', Average Order Value: $', avg_order_value::STRING,
        '. Include key insights and recommendations.'
    ),
    {'temperature': 0.3}  -- More factual
) as executive_summary
FROM sales_metrics;
```

### Code Generation

#### SQL Query Generation
```sql
-- Generate SQL queries from natural language
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'reka-core',  -- Specialized for code
    CONCAT(
        'Generate a SQL query for the following request: ',
        user_request,
        ' Schema information: ', table_schema
    )
) as generated_sql
FROM query_requests;
```

#### Data Transformation Logic
```sql
-- Generate transformation rules
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'claude-3-5-sonnet',
    CONCAT(
        'Create data transformation logic to convert ',
        source_format, ' to ', target_format,
        '. Sample data: ', sample_data
    )
) as transformation_logic
FROM transformation_tasks;
```

### Documentation & Explanations

#### Technical Documentation
```sql
-- Generate API documentation
SELECT 
    function_name,
    SNOWFLAKE.CORTEX.COMPLETE(
        'claude-3-5-sonnet',
        CONCAT(
            'Write technical documentation for this function: ',
            function_name, ' Parameters: ', parameters,
            ' Purpose: ', function_purpose,
            ' Include usage examples and best practices.'
        )
    ) as documentation
FROM api_functions;
```

## Batch Processing Patterns

### Processing Large Datasets
```sql
-- Process in batches to manage costs and performance
CREATE OR REPLACE PROCEDURE process_completions_batch(batch_size INTEGER)
RETURNS STRING
LANGUAGE SQL
AS $$
DECLARE
    processed_count INTEGER := 0;
    total_batches INTEGER;
BEGIN
    SELECT CEIL(COUNT(*) / batch_size) INTO total_batches
    FROM pending_completions;
    
    FOR batch_num IN 1 TO total_batches DO
        INSERT INTO completed_tasks
        SELECT 
            id,
            input_text,
            SNOWFLAKE.CORTEX.COMPLETE('llama3.1-70b', input_text) as completion,
            CURRENT_TIMESTAMP() as processed_at
        FROM (
            SELECT * FROM pending_completions
            WHERE processed = FALSE
            LIMIT batch_size
        );
        
        UPDATE pending_completions 
        SET processed = TRUE
        WHERE id IN (
            SELECT id FROM pending_completions
            WHERE processed = FALSE
            LIMIT batch_size
        );
        
        SET processed_count = processed_count + batch_size;
    END FOR;
    
    RETURN 'Processed ' || processed_count || ' completions';
END;
$$;
```

### Parallel Processing with Different Models
```sql
-- Route different types of tasks to appropriate models
INSERT INTO completions_results
SELECT 
    task_id,
    task_type,
    input_text,
    CASE task_type
        WHEN 'creative_writing' THEN 
            SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', input_text, {'temperature': 0.8})
        WHEN 'data_analysis' THEN 
            SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', input_text, {'temperature': 0.2})
        WHEN 'code_generation' THEN 
            SNOWFLAKE.CORTEX.COMPLETE('reka-core', input_text)
        WHEN 'simple_qa' THEN 
            SNOWFLAKE.CORTEX.COMPLETE('llama3.1-8b', input_text)
        ELSE 
            SNOWFLAKE.CORTEX.COMPLETE('llama3.1-70b', input_text)
    END as completion
FROM completion_tasks
WHERE status = 'pending';
```

## Error Handling & Monitoring

### Robust Error Handling
```sql
-- Handle various error conditions
SELECT 
    request_id,
    input_text,
    CASE 
        WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', input_text) > 4000 THEN
            'Input too long for processing'
        WHEN LENGTH(input_text) < 10 THEN
            'Input too short for meaningful completion'
        ELSE
            COALESCE(
                SNOWFLAKE.CORTEX.TRY_COMPLETE('llama3.1-70b', input_text),
                'Completion failed - please retry'
            )
    END as safe_completion
FROM user_requests;
```

### Usage Monitoring
```sql
-- Monitor completion usage and costs
SELECT 
    DATE_TRUNC('hour', timestamp) as hour,
    model_name,
    COUNT(*) as request_count,
    SUM(input_tokens) as total_input_tokens,
    SUM(output_tokens) as total_output_tokens,
    AVG(latency_ms) as avg_latency
FROM TABLE(INFORMATION_SCHEMA.CORTEX_FUNCTIONS_USAGE_HISTORY(
    DATE_ADD('day', -7, CURRENT_DATE()),
    CURRENT_DATE()
))
WHERE function_name = 'COMPLETE'
GROUP BY 1, 2
ORDER BY 1 DESC, 3 DESC;
```

## Performance Optimization

### Model Selection Strategy
```sql
-- Choose optimal model based on task complexity
CREATE OR REPLACE FUNCTION select_optimal_model(task_type STRING, complexity_score INTEGER)
RETURNS STRING
AS $$
    CASE 
        WHEN task_type = 'simple_qa' AND complexity_score < 3 THEN 'llama3.1-8b'
        WHEN task_type = 'analysis' AND complexity_score >= 7 THEN 'claude-3-5-sonnet'
        WHEN task_type = 'code' THEN 'reka-core'
        WHEN complexity_score >= 8 THEN 'mistral-large2'
        WHEN complexity_score >= 5 THEN 'llama3.1-70b'
        ELSE 'llama3.1-8b'
    END
$$;
```

### Caching Results
```sql
-- Cache completions to avoid reprocessing
CREATE TABLE completion_cache (
    prompt_hash STRING,
    model_name STRING,
    completion_result STRING,
    created_at TIMESTAMP,
    PRIMARY KEY (prompt_hash, model_name)
);

-- Use cached results when available
WITH cached_result AS (
    SELECT completion_result
    FROM completion_cache
    WHERE prompt_hash = SHA2(?, 256) AND model_name = ?
    AND created_at > DATEADD('day', -7, CURRENT_TIMESTAMP())
)
SELECT 
    COALESCE(
        (SELECT completion_result FROM cached_result),
        SNOWFLAKE.CORTEX.COMPLETE(?, ?)
    ) as final_result;
```

## ðŸ’° **Cost Considerations and Management**

### **Credit-Based Billing Model**
Based on the [official Snowflake AISQL cost documentation](https://docs.snowflake.com/en/user-guide/snowflake-cortex/aisql#label-cortex-llm-cost-considerations), AISQL functions use a token-based credit consumption model:

#### **Token-Based Pricing**
- **Input tokens**: Counted for all AISQL functions
- **Output tokens**: Counted for generative functions (AI_COMPLETE, COMPLETE, CHAT, SUMMARIZE)
- **Processing tokens**: Only input tokens counted for analysis functions (SENTIMENT, CLASSIFY, EXTRACT_ANSWER)

#### **Credit Consumption Rates**
```sql
-- Monitor credit consumption by model
SELECT 
    model_name,
    function_name,
    SUM(input_tokens) as total_input_tokens,
    SUM(output_tokens) as total_output_tokens,
    SUM(credits_consumed) as total_credits
FROM TABLE(INFORMATION_SCHEMA.CORTEX_FUNCTIONS_USAGE_HISTORY(
    DATE_ADD('day', -30, CURRENT_DATE()),
    CURRENT_DATE()
))
GROUP BY model_name, function_name
ORDER BY total_credits DESC;
```

### **Cost Tracking and Monitoring**

#### **Account Usage Views**
Monitor AISQL function costs across your organization:

```sql
-- Track costs for AI services across account
SELECT 
    DATE_TRUNC('day', start_time) as usage_date,
    user_name,
    warehouse_name,
    function_name,
    model_name,
    SUM(credits_used) as daily_credits,
    COUNT(*) as function_calls,
    SUM(input_tokens) as total_input_tokens,
    SUM(output_tokens) as total_output_tokens
FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_USAGE
WHERE start_time >= DATEADD('month', -1, CURRENT_DATE())
GROUP BY 1, 2, 3, 4, 5
ORDER BY usage_date DESC, daily_credits DESC;
```

#### **Real-Time Usage Monitoring**
```sql
-- Real-time cost tracking during processing
CREATE OR REPLACE TABLE cortex_cost_tracker (
    session_id STRING,
    function_call_id STRING,
    model_name STRING,
    input_token_count NUMBER,
    estimated_cost DECIMAL(10,6),
    actual_credits_used DECIMAL(10,6),
    timestamp TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP()
);

-- Log costs before function execution
INSERT INTO cortex_cost_tracker
SELECT 
    CURRENT_SESSION(),
    RANDOM()::STRING,
    'llama3.1-70b',
    SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', input_text),
    SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', input_text) * 0.0001, -- Estimated rate
    NULL,
    CURRENT_TIMESTAMP()
FROM processing_queue;
```

### **Usage Quotas and Limits**

#### **Model-Specific Limits**
Each model has different token limits and associated costs:

```sql
-- Pre-flight check for token limits
SELECT 
    request_id,
    model_name,
    input_text,
    SNOWFLAKE.CORTEX.COUNT_TOKENS(model_name, input_text) as token_count,
    CASE 
        WHEN model_name = 'llama3.1-405b' AND SNOWFLAKE.CORTEX.COUNT_TOKENS(model_name, input_text) > 100000 THEN 'Exceeds limit'
        WHEN model_name = 'claude-3.5-sonnet' AND SNOWFLAKE.CORTEX.COUNT_TOKENS(model_name, input_text) > 200000 THEN 'Exceeds limit'
        WHEN model_name = 'llama3.1-8b' AND SNOWFLAKE.CORTEX.COUNT_TOKENS(model_name, input_text) > 128000 THEN 'Exceeds limit'
        ELSE 'Within limits'
    END as status
FROM user_requests;
```

#### **Account-Level Quotas**
```sql
-- Set up resource monitors for AISQL cost control
CREATE OR REPLACE RESOURCE MONITOR cortex_monthly_limit
WITH 
    CREDIT_QUOTA = 500  -- Monthly AISQL credit limit
    FREQUENCY = MONTHLY
    START_TIMESTAMP = CURRENT_TIMESTAMP()
    TRIGGERS 
        ON 75 PERCENT DO NOTIFY
        ON 90 PERCENT DO SUSPEND
        ON 100 PERCENT DO SUSPEND_IMMEDIATE;
```

### **Cost Optimization Strategies**

#### **1. Model Selection by Cost Efficiency**
```sql
-- Cost-optimized model selection logic
CREATE OR REPLACE FUNCTION select_cost_optimal_model(task_complexity STRING, budget_tier STRING)
RETURNS STRING
AS $$
    CASE 
        WHEN task_complexity = 'simple' AND budget_tier = 'low' THEN 'llama3.1-8b'
        WHEN task_complexity = 'simple' AND budget_tier = 'medium' THEN 'mistral-7b'
        WHEN task_complexity = 'medium' AND budget_tier = 'low' THEN 'llama3.1-8b'
        WHEN task_complexity = 'medium' AND budget_tier = 'medium' THEN 'llama3.1-70b'
        WHEN task_complexity = 'complex' AND budget_tier = 'medium' THEN 'claude-3.5-sonnet'
        WHEN task_complexity = 'complex' AND budget_tier = 'high' THEN 'llama3.1-405b'
        ELSE 'llama3.1-70b'  -- Default balanced option
    END
$$;

-- Apply cost-optimal model selection
SELECT 
    task_id,
    select_cost_optimal_model(task_complexity, budget_tier) as selected_model,
    SNOWFLAKE.CORTEX.COMPLETE(
        select_cost_optimal_model(task_complexity, budget_tier),
        task_prompt
    ) as result
FROM tasks_queue;
```

#### **2. Token Usage Optimization**
```sql
-- Optimize prompts to reduce token consumption
WITH prompt_optimization AS (
    SELECT 
        original_prompt,
        -- Shortened version for cost efficiency
        CASE 
            WHEN LENGTH(original_prompt) > 1000 THEN 
                LEFT(original_prompt, 800) || '...[truncated for efficiency]'
            ELSE original_prompt
        END as optimized_prompt,
        SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', original_prompt) as original_tokens,
        SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', 
            CASE 
                WHEN LENGTH(original_prompt) > 1000 THEN 
                    LEFT(original_prompt, 800) || '...[truncated for efficiency]'
                ELSE original_prompt
            END
        ) as optimized_tokens
    FROM user_prompts
)
SELECT 
    *,
    (original_tokens - optimized_tokens) as tokens_saved,
    (original_tokens - optimized_tokens) * 0.0001 as estimated_cost_savings
FROM prompt_optimization
WHERE tokens_saved > 0;
```

#### **3. Caching and Result Reuse**
```sql
-- Implement intelligent caching to avoid duplicate calls
CREATE OR REPLACE TABLE cortex_cache (
    prompt_hash STRING,
    model_name STRING,
    cached_response VARIANT,
    tokens_used NUMBER,
    created_timestamp TIMESTAMP_NTZ,
    access_count NUMBER DEFAULT 1
);

-- Cache lookup before making AISQL calls
CREATE OR REPLACE FUNCTION get_cached_or_complete(prompt_text STRING, model STRING)
RETURNS VARIANT
LANGUAGE SQL
AS $$
DECLARE
    cached_result VARIANT;
    prompt_hash STRING := SHA2(prompt_text || model);
BEGIN
    -- Check cache first
    SELECT cached_response INTO cached_result
    FROM cortex_cache 
    WHERE prompt_hash = :prompt_hash 
    AND model_name = :model
    AND created_timestamp > DATEADD('hour', -24, CURRENT_TIMESTAMP());
    
    -- Return cached result if found
    IF (cached_result IS NOT NULL) THEN
        UPDATE cortex_cache 
        SET access_count = access_count + 1 
        WHERE prompt_hash = :prompt_hash AND model_name = :model;
        RETURN cached_result;
    END IF;
    
    -- Make new AISQL call and cache result
    cached_result := SNOWFLAKE.CORTEX.COMPLETE(:model, :prompt_text);
    INSERT INTO cortex_cache 
    VALUES (:prompt_hash, :model, cached_result, 
            SNOWFLAKE.CORTEX.COUNT_TOKENS(:model, :prompt_text), 
            CURRENT_TIMESTAMP(), 1);
    
    RETURN cached_result;
END;
$$;
```

### **Managing Costs and Throttling**

#### **Rate Limiting Implementation**
```sql
-- Implement rate limiting to control costs
CREATE OR REPLACE TABLE rate_limits (
    user_name STRING,
    function_calls_per_hour NUMBER DEFAULT 100,
    credits_per_day NUMBER DEFAULT 10.0,
    current_hour_calls NUMBER DEFAULT 0,
    current_day_credits NUMBER DEFAULT 0.0,
    last_reset_hour TIMESTAMP_NTZ,
    last_reset_day TIMESTAMP_NTZ
);

-- Check rate limits before function execution
CREATE OR REPLACE FUNCTION check_rate_limit(user STRING)
RETURNS BOOLEAN
LANGUAGE SQL
AS $$
DECLARE
    current_calls NUMBER;
    current_credits NUMBER;
    can_proceed BOOLEAN := FALSE;
BEGIN
    -- Reset counters if needed
    UPDATE rate_limits 
    SET 
        current_hour_calls = CASE 
            WHEN last_reset_hour < DATE_TRUNC('hour', CURRENT_TIMESTAMP()) THEN 0 
            ELSE current_hour_calls 
        END,
        current_day_credits = CASE 
            WHEN last_reset_day < DATE_TRUNC('day', CURRENT_TIMESTAMP()) THEN 0.0 
            ELSE current_day_credits 
        END,
        last_reset_hour = CASE 
            WHEN last_reset_hour < DATE_TRUNC('hour', CURRENT_TIMESTAMP()) THEN CURRENT_TIMESTAMP() 
            ELSE last_reset_hour 
        END,
        last_reset_day = CASE 
            WHEN last_reset_day < DATE_TRUNC('day', CURRENT_TIMESTAMP()) THEN CURRENT_TIMESTAMP() 
            ELSE last_reset_day 
        END
    WHERE user_name = :user;
    
    -- Check current usage
    SELECT current_hour_calls, current_day_credits 
    INTO current_calls, current_credits
    FROM rate_limits 
    WHERE user_name = :user;
    
    -- Determine if user can proceed
    can_proceed := (current_calls < 100 AND current_credits < 10.0);
    
    RETURN can_proceed;
END;
$$;
```

#### **Cost Alerting System**
```sql
-- Automated cost alerting
CREATE OR REPLACE PROCEDURE monitor_cortex_costs()
RETURNS STRING
LANGUAGE SQL
AS $$
DECLARE
    daily_spend NUMBER;
    monthly_spend NUMBER;
    alert_message STRING := '';
BEGIN
    -- Calculate daily spend
    SELECT COALESCE(SUM(credits_used), 0) INTO daily_spend
    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_USAGE
    WHERE DATE(start_time) = CURRENT_DATE();
    
    -- Calculate monthly spend
    SELECT COALESCE(SUM(credits_used), 0) INTO monthly_spend
    FROM SNOWFLAKE.ACCOUNT_USAGE.CORTEX_FUNCTIONS_USAGE
    WHERE start_time >= DATE_TRUNC('month', CURRENT_DATE());
    
    -- Generate alerts based on thresholds
    IF (daily_spend > 50) THEN
        alert_message := 'ALERT: Daily AISQL spending exceeded $50 (' || daily_spend || ' credits)';
        -- Could integrate with notification system here
    END IF;
    
    IF (monthly_spend > 500) THEN
        alert_message := alert_message || '\nALERT: Monthly AISQL spending exceeded $500 (' || monthly_spend || ' credits)';
    END IF;
    
    RETURN COALESCE(alert_message, 'Cost monitoring: All within limits');
END;
$$;
```

### **Best Practices for Cost Management**

#### **1. Pre-Processing Optimization**
```sql
-- Batch processing to reduce per-call overhead
SELECT 
    batch_id,
    SNOWFLAKE.CORTEX.COMPLETE(
        'llama3.1-70b',
        'Process the following batch of texts:\n' || 
        LISTAGG(input_text, '\n---\n') WITHIN GROUP (ORDER BY priority)
    ) as batch_results
FROM (
    SELECT 
        FLOOR((ROW_NUMBER() OVER (ORDER BY created_date)) / 10) as batch_id,
        input_text,
        priority
    FROM processing_queue
    WHERE status = 'pending'
)
GROUP BY batch_id;
```

#### **2. Smart Model Routing**
```sql
-- Route requests to cost-appropriate models
CREATE OR REPLACE VIEW cost_optimized_routing AS
SELECT 
    request_id,
    input_text,
    CASE 
        WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-8b', input_text) < 100 
             AND complexity_score < 0.3 THEN 'llama3.1-8b'    -- Cheapest for simple tasks
        WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', input_text) < 1000 
             AND complexity_score < 0.7 THEN 'llama3.1-70b'   -- Balanced option
        ELSE 'claude-3.5-sonnet'                              -- Premium for complex tasks
    END as optimal_model,
    CASE 
        WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-8b', input_text) < 100 
             AND complexity_score < 0.3 THEN 0.0001
        WHEN SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', input_text) < 1000 
             AND complexity_score < 0.7 THEN 0.0005
        ELSE 0.002
    END as estimated_cost_per_token
FROM user_requests;
```

#### **3. Cost-Aware Error Handling**
```sql
-- Implement progressive fallback to control costs
CREATE OR REPLACE FUNCTION cost_aware_complete(prompt_text STRING, max_budget NUMBER)
RETURNS VARIANT
LANGUAGE SQL
AS $$
DECLARE
    result VARIANT;
    estimated_cost NUMBER;
BEGIN
    -- Try cheapest model first
    estimated_cost := SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-8b', prompt_text) * 0.0001;
    IF (estimated_cost <= max_budget) THEN
        result := SNOWFLAKE.CORTEX.TRY_COMPLETE('llama3.1-8b', prompt_text);
        IF (result IS NOT NULL) THEN RETURN result; END IF;
    END IF;
    
    -- Fallback to medium model if budget allows
    estimated_cost := SNOWFLAKE.CORTEX.COUNT_TOKENS('llama3.1-70b', prompt_text) * 0.0005;
    IF (estimated_cost <= max_budget) THEN
        result := SNOWFLAKE.CORTEX.TRY_COMPLETE('llama3.1-70b', prompt_text);
        IF (result IS NOT NULL) THEN RETURN result; END IF;
    END IF;
    
    -- Return error if budget exceeded
    RETURN OBJECT_CONSTRUCT('error', 'Budget exceeded for request');
END;
$$;
```

## Study Questions

1. **Which function should you use for error-safe LLM completions?**
   - A) COMPLETE()
   - B) TRY_COMPLETE()
   - C) SAFE_COMPLETE()
   - D) ERROR_COMPLETE()

2. **What parameter controls the randomness of generated text?**
   - A) max_tokens
   - B) top_p
   - C) temperature
   - D) creativity

3. **Which model is most cost-effective for simple question-answering tasks?**
   - A) claude-3-5-sonnet
   - B) mistral-large2
   - C) llama3.1-70b
   - D) llama3.1-8b

**Answers: 1-B, 2-C, 3-D**

***
[< Domain 2 Overview](./README.md) | **2.2 Cortex LLM Complete Functions** | [Cortex Chat Functions >](./2.3_Cortex_Chat_Functions.md) 